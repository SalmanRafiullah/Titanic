{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reference:\n1. Titanic: Feature Engineering & Logistic Regression - https://www.kaggle.com/matheuscoradini/titanic-feature-engineering-logistic-regression\n2. Python Logistic regression - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedKFold\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_nan(df):\n    for i in df.Sex.unique():\n        for j in df.Pclass.unique():\n            x = df.loc[((df.Sex == i) & (df.Pclass == j)), 'Age'].mean()\n            df.loc[((df.Sex == i) & (df.Pclass == j)), 'Age'] = df.loc[((df.Sex == i) & (df.Pclass == j)), 'Age'].fillna(x)\n\nage_nan(train_data)\nage_nan(test_data)\n\n# fill NaN values of Embarked with 'S', because it's the most commom value for it\n\ntrain_data['Embarked'] = train_data['Embarked'].fillna('S')\ntest_data['Embarked'] = test_data['Embarked'].fillna('S')\n\n\ntrain_data['Cabin_NaN'] = train_data['Cabin'].isnull().astype(int)\ntest_data['Cabin_NaN'] = test_data['Cabin'].isnull().astype(int)\n\n\ntest_data.Fare = test_data.Fare.fillna(-1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_female(x):\n    if x == 'female':\n        return 1\n    else:\n        return 0\n\ntrain_data['Sex_bin'] = train_data['Sex'].map(is_female)\ntest_data['Sex_bin'] = test_data['Sex'].map(is_female)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def embarked_s(x):\n    if x == 'S':\n        return 1\n    else:\n        return 0\n\ntrain_data['Embarked_S'] = train_data['Embarked'].map(embarked_s)\ntest_data['Embarked_S'] = test_data['Embarked'].map(embarked_s)\n\ndef embarked_c(x):\n    if x == 'C':\n        return 1\n    else:\n        return 0\n    \ntrain_data['Embarked_C'] = train_data['Embarked'].map(embarked_c)\ntest_data['Embarked_C'] = test_data['Embarked'].map(embarked_c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sex_Count = train_data.groupby([\"Survived\",\"Sex\"])[\"Sex\"].count()#\nPclass = train_data.groupby([\"Survived\",\"Pclass\"])[\"Pclass\"].count()\n# 3 class died a lot more\nAge = train_data.groupby([\"Survived\",\"Age\"])[\"Age\"].count()\nSibSp = train_data.groupby([\"Survived\",\"SibSp\"])[\"SibSp\"].count()\n# 1 sibling have more chanvce to survive\nParch = train_data.groupby([\"Survived\",\"Parch\"])[\"Parch\"].count()\nTicket = train_data.groupby([\"Survived\",\"Ticket\"])[\"Ticket\"].count()\nFare = train_data.groupby([\"Survived\",\"Fare\"])[\"Fare\"].count()\nCabin = train_data.groupby([\"Survived\",\"Cabin\"])[\"Cabin\"].count()\nEmbarked = train_data.groupby([\"Survived\",\"Embarked\"])[\"Embarked\"].count()\n# C died more, S died less\n\nprint(Sex_Count,Pclass,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = ['Age', 'Sex_bin', 'Pclass', 'Fare', 'SibSp', 'Parch', 'Embarked_S','Embarked_C', 'Cabin_NaN']\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\nclf = LogisticRegression(random_state=0,max_iter=500).fit(X, y)\npredictions = clf.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}